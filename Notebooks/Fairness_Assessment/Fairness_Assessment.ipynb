{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade raiwidgets\n",
    "# %pip install --upgrade pandas\n",
    "# %pip install --upgrade fairlearn\n",
    "# %pip install --upgrade interpret-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing packages, you must close and reopen the notebook as well as restarting the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness Assessment** powered by [Fairlearn](https://github.com/fairlearn/fairlearn), which identifies which groups of people may be disproportionately negatively impacted by an AI system and in what ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from raiwidgets import FairnessDashboard\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_dataset():\n",
    "    file_path = \"/home/josh/Downloads/AiDashOwnModels/Acidents_dataset_v7.csv\"\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    return dataset\n",
    "\n",
    "# Call the function to load dataset\n",
    "df = load_custom_dataset()\n",
    "\n",
    "# Check for missing values\n",
    "if df.isnull().sum().any():\n",
    "    print(\"Missing values detected in the dataset.\")\n",
    "else:\n",
    "    print(\"No missing values in the dataset.\")\n",
    "\n",
    "# Display first few rows to verify\n",
    "print(df.head())\n",
    "\n",
    "# Select target column (label) and features\n",
    "X_Raw = df\n",
    "y_true = (df['Degree of Injury'] == 'Fatal').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_features = X_Raw[['Nature of Injury', 'Part of Body']]\n",
    "X = X_Raw.drop(labels=['Nature of Injury', 'Part of Body'], axis=1)\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Scale the features\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_true = le.fit_transform(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, sensitive_features_train, sensitive_features_test = \\\n",
    "    train_test_split(X_scaled, y_true, sensitive_features,\n",
    "                     test_size=0.2, random_state=0, stratify=y_true)\n",
    "\n",
    "# Work around indexing bug\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "sensitive_features_train = sensitive_features_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "sensitive_features_test = sensitive_features_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "unmitigated_predictor = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
    "unmitigated_predictor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = unmitigated_predictor.predict(X_test)\n",
    "\n",
    "# Check predictions\n",
    "print(\"Unique values in y_test:\", set(y_test))\n",
    "print(\"Unique values in y_pred:\", set(y_pred))\n",
    "# Launch the Fairness Dashboard\n",
    "FairnessDashboard(sensitive_features=sensitive_features_test,\n",
    "                  y_true=y_test,\n",
    "                  y_pred=y_pred,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â© Copyright, 2025 Assentian Limited. All Rights Reserved "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
